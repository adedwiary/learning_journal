{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCKRVeG7Rz1D"
      },
      "source": [
        "# Week 3: Day 5 AM // Web Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Web scraping : mengekstrak data dari sebuah web.\n",
        "\n",
        "Selenium : tools untuk automatisasi, untuk ambil data\n",
        "\n",
        "https://github.com/MariyaSha/WebscrapingInstagram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a29ae3TSlhnI"
      },
      "source": [
        "## Tools Preparation\n",
        "Scrapping is basically one of the way to retrieve the data and this process is very important to know as a data scientist since sometimes we cannot get data easily as we querying the data from the database or download Kaggle. We're going to scrape Gramedia.com in this lesson using Beautifulsoup. Before we're going further, please install beautifulsoup.\n",
        "\n",
        "To install beautifulsoup, you may run one of the following commands on Anaconda Prompt (Windows) or Terminal (Linux/Mac/VSCode):\n",
        "\n",
        "```\n",
        "pip install bs4\n",
        "```\n",
        "\n",
        "and also you need to install requests to acces a web address by running:\n",
        "\n",
        "```\n",
        "pip install requests\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (2.26.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py): started\n",
            "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=46a0c2dced65ae282b9acd84357ea2b5c34bc5865ea05e0ac02104f89120d461\n",
            "  Stored in directory: c:\\users\\dedwi\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmZE8li0lhnJ"
      },
      "source": [
        "## Basic Web Component\n",
        "\n",
        "The website that you are scraping in this lesson contains several components. Those are:\n",
        "- HTML — the main content of the page.\n",
        "- CSS — used to add styling to make the page look nicer.\n",
        "- JS — Javascript files add interactivity to web pages.\n",
        "- Images — image formats, such as JPG and PNG, allow web pages to show pictures.\n",
        "\n",
        "There’s a lot that happens behind the scenes to render a page nicely, but we don’t need to worry about most of it when we’re web scraping. When we perform web scraping, we’re interested in the main content of the web page, so we look primarily at the HTML. Hence, you need to know some HTML structure to ease your scraping works. But don't worry, you don't need to dive in deeply into it.\n",
        "\n",
        "### HTML Structure\n",
        "\n",
        "HyperText Markup Language (HTML) is the language that web pages are created in. HTML isn’t a programming language, like Python, though. It’s a markup language that tells a browser how to display content. \n",
        "\n",
        "HTML has many functions that are similar to what you might find in a word processor like Microsoft Word — it can make text bold, create paragraphs, and so on.\n",
        "\n",
        "Below an example of HTML structure:\n",
        "\n",
        "```html\n",
        "<HTML>\n",
        "    <HEAD>\n",
        "        <TITLE>My cool title</TITLE>\n",
        "    </HEAD>\n",
        "    <BODY>\n",
        "        <H1>This is a Header</H1>\n",
        "        <ul id=\"list\" class=\"coolList\">\n",
        "            <li>item 1</li>\n",
        "            <li>item 2</li>\n",
        "            <li>item 3</li>\n",
        "        </ul>\n",
        "    </BODY>\n",
        "</HTML>\n",
        "```\n",
        "\n",
        "- The red items are called as tag or element. Usually, tag follows \"<\".\n",
        "- HTML, HEAD, and BODY are the main elements and the rests are the content. For your attention, we will focus on the contents.\n",
        "- The orange items are attribut that give information about the tag.\n",
        "- The blue texts are the attribute value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujkN7JiWlhnK"
      },
      "source": [
        "## Accessing the Web\n",
        "\n",
        "Now, we will access https://www.gramedia.com/categories/buku for this lesson. Before we go further, we need to understand how to access the url in Python. To do it, we use requests library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bJQlflU3lhnK",
        "outputId": "9eddeac5-0d9b-43ea-cf43-552317557360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests #menampilkan respon\n",
        "page = requests.get(\"https://www.gramedia.com/categories/buku\")\n",
        "page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inTIzZZylhnP"
      },
      "source": [
        "If you see the output is <Response [200]>, then you are success to access the url. \"200\" refers to HTTP status codes. You can read https://id.wikipedia.org/wiki/Daftar_kode_status_HTTP for further explaination.\n",
        "\n",
        "Now, you can check the HTML content of the page in Python. However, you can also check it on your browser by right click and choose Inspect element to ease your understanding od the web structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLKOMDKKlhnP"
      },
      "source": [
        "Above is the HTML structure that Python successfully access. We need to parsing the structure using Beautifulsoup to make it clear and accessible to scrape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
            "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
            "Collecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
            "Requirement already satisfied: idna in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: pycparser in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.8)\n",
            "Requirement already satisfied: certifi in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.5.2 in c:\\users\\dedwi\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.16.0)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.13.0 outcome-1.1.0 selenium-4.1.0 trio-0.19.0 trio-websocket-0.9.2 wsproto-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NJRYl45GlhnQ",
        "outputId": "72138b87-7813-4143-f169-cae0259ea96a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dedwi\\AppData\\Local\\Temp/ipykernel_20652/2446386098.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome('./web_scraping/chromedriver.exe')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<html class=\"\" lang=\"id\">\n",
            " <head>\n",
            "  <base href=\"/\"/>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
            "  <meta content=\"#281e5a\" name=\"theme-color\"/>\n",
            "  <meta content=\"index, follow\" name=\"robots\"/>\n",
            "  <link href=\"/assets/favicon.ico\" rel=\"icon\" type=\"image/x-icon\"/>\n",
            "  <link href=\"manifest.json\" rel=\"manifest\"/>\n",
            "  <link href=\"/assets/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
            "  <meta content=\"z91Vp6ZYo9UoX5D4ur6i4Lrl0l1j3DDoCH08fD3n53g\" name=\"google-site-verification\"/>\n",
            "  <meta content=\"810657685650228\" property=\"fb:app_id\"/>\n",
            "  <style>\n",
            "   .async-hide {\n",
            "        opacity: 0 !important\n",
            "    }\n",
            "  </style>\n",
            "  <script async=\"\" src=\"https://app.\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "driver = webdriver.Chrome('./web_scraping/chromedriver.exe')\n",
        "\n",
        "url=\"https://www.gramedia.com/categories/buku\"\n",
        "driver.get(url)\n",
        "html = driver.page_source\n",
        "\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "print(soup.prettify()[:700])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNDQDGeklhnR"
      },
      "source": [
        "<img src=\"https://i.ibb.co/vsz2M33/message-Image-1636690176458.jpg\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POMWjvBylhnR"
      },
      "source": [
        "Let that we want to retrieve the books' title, so let's check the title position on the HTML out using Inspect element!\n",
        "\n",
        "We know that based on the Inspect element, the books' title lie on this code:\n",
        "\n",
        "```html\n",
        "<div _ngcontent-web-gramedia-c53=\"\" class=\"list-title\">Creepy Case Club 4: Kasus Pohon Pemanggil</div>\n",
        "```\n",
        "\n",
        "\"Creepy Case Club 4: Kasus Pohon Pemanggil\" located at **div** tag with attribute **class** and the value of \"*list-title*\". So we will use the information to inform the soup where the titles exist.\n",
        "\n",
        "So we need to find all div elements that contain attribute class and value \"list-title\". \n",
        "\n",
        "To do that, we use ```soup.find_all(\"<element>\",{\"<attribute>\":\"<attribute value>\"})```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6laOggk9lhnS",
        "outputId": "88456a2c-5515-4ace-c662-5ca8c4848e60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">A+</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Lavender</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Fiqih Al-Mu`Tamad Fiqih Hukum Keluarga Jilid 4</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">30 Doa Salafush Shalih</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Ramuan Tradisional Anti Segala Virus</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Malaikat Di Sisi Kita</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Buku Bisakah Aku yang Pelupa Memiliki Ingatan Super?</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">The Art of Self Talk-ing</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Paket Pandai Baca Tulis Hitung Anak Umur Paud / Tk</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Kisah 25 Nabi Dan Khulafaur Rasyidin</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Indonesia Sebagai Poros Maritim Dunia</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Kitab Lulus Utbk Sbmptn Saintek 2022</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Pendidikan Untuk Apa dan Untuk Siapa?</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Petualangan Lu si Ulat Bulu : Topi Jerami Lu</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Petualangan Lu si Ulat Bulu : Apakah Lu diculik?</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Kenduri Arwah</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Intelijen dan Kekuasaan Soeharto</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Petualangan Lu si Ulat Bulu : Kenari Untuk Pipu</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">KOLONI Sinawang</div>,\n",
              " <div _ngcontent-web-gramedia-c26=\"\" class=\"list-title\">Plants VS Zombies - Komik Dinosaurus : Berburu Harta Karun di Periode Jura</div>]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "soup.find_all('div',{\"class\":\"list-title\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AytjhC7zlhnS"
      },
      "source": [
        "We see that the soup found all div elements that contain attribute class and value \"list-title\" but we need the title text only. To extract it, just add .get_text() method to each list element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s12s2vjQlhnS",
        "outputId": "1c112551-50ba-4dbc-b081-c4c0bf86404e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A+\n",
            "Lavender\n",
            "Fiqih Al-Mu`Tamad Fiqih Hukum Keluarga Jilid 4\n",
            "30 Doa Salafush Shalih\n",
            "Ramuan Tradisional Anti Segala Virus\n",
            "Malaikat Di Sisi Kita\n",
            "Buku Bisakah Aku yang Pelupa Memiliki Ingatan Super?\n",
            "The Art of Self Talk-ing\n",
            "Paket Pandai Baca Tulis Hitung Anak Umur Paud / Tk\n",
            "Kisah 25 Nabi Dan Khulafaur Rasyidin\n",
            "Indonesia Sebagai Poros Maritim Dunia\n",
            "Kitab Lulus Utbk Sbmptn Saintek 2022\n",
            "Pendidikan Untuk Apa dan Untuk Siapa?\n",
            "Petualangan Lu si Ulat Bulu : Topi Jerami Lu\n",
            "Petualangan Lu si Ulat Bulu : Apakah Lu diculik?\n",
            "Kenduri Arwah\n",
            "Intelijen dan Kekuasaan Soeharto\n",
            "Petualangan Lu si Ulat Bulu : Kenari Untuk Pipu\n",
            "KOLONI Sinawang\n",
            "Plants VS Zombies - Komik Dinosaurus : Berburu Harta Karun di Periode Jura\n"
          ]
        }
      ],
      "source": [
        "for div_tag in soup.find_all('div',{\"class\":\"list-title\"}):\n",
        "    print(div_tag.get_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEB1TyTOlhnT"
      },
      "source": [
        "It is easy, isn't it?\n",
        "\n",
        "Next, we will do more. Our task is to get information about Title, Author, Price, Link to the book's page, and link refers to image.\n",
        "\n",
        "Based on the Inspect element, we know that those information locate on:\n",
        "- Title: ```<div _ngcontent-web-gramedia-c53=\"\" class=\"list-title\">Creepy Case Club 4: Kasus Pohon Pemanggil</div>```\n",
        "- Author: ```<p class=\"div-author\"><span _ngcontent-web-gramedia-c53=\"\" class=\"list-author ng-star-inserted\"> Arvidan None </span>```\n",
        "- Price: ```<p _ngcontent-web-gramedia-c53=\"\" class=\"formats-price\">Rp 79.000</p>```\n",
        "- Link: ```<div class=\"ng-star-inserted\"><a _ngcontent-web-gramedia-c53=\"\" href=\"/products/think-and-grow-rich-cara-para-jutawan-dan-miliarder-meraih-kekayaan\">```\n",
        "- Image: ```<img _ngcontent-web-gramedia-c26=\"\" class=\"product-list-img ng-star-inserted ng-lazyloaded\" src=\"https://cdn.gramedia.com/uploads/items/9786230405990_Think_and_Grow_Rich__w149_hauto.jpeg\" alt=\"Think And Grow Rich : Cara Para Jutawan Dan Miliarder Meraih Kekayaan\">```\n",
        "\n",
        "Let's we wrap up the code and then input the data into Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yPM2xEnFlhnT",
        "outputId": "a103c45b-2ebf-470c-ed88-ebfcc508fca1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Author</th>\n",
              "      <th>Price</th>\n",
              "      <th>Image</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A+</td>\n",
              "      <td>Ananda Putri</td>\n",
              "      <td>Rp 84.575</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/A__w149...</td>\n",
              "      <td>https://www.gramedia.com/products/a-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lavender</td>\n",
              "      <td>Astri Salvia Aznani</td>\n",
              "      <td>Rp 80.750</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/Lavende...</td>\n",
              "      <td>https://www.gramedia.com/products/lavender</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fiqih Al-Mu`Tamad Fiqih Hukum Keluarga Jilid 4</td>\n",
              "      <td>Prof. Dr. Muhammad az-Zuhaili</td>\n",
              "      <td>Rp 204.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/fiqih-al-mut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30 Doa Salafush Shalih</td>\n",
              "      <td>OMAR None</td>\n",
              "      <td>Rp 58.650</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/30_Doa_...</td>\n",
              "      <td>https://www.gramedia.com/products/30-doa-salaf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ramuan Tradisional Anti Segala Virus</td>\n",
              "      <td>Argo Wikanjati</td>\n",
              "      <td>Rp 51.000</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/Ramuan_...</td>\n",
              "      <td>https://www.gramedia.com/products/ramuan-tradi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Malaikat Di Sisi Kita</td>\n",
              "      <td>Omar Suleman</td>\n",
              "      <td>Rp 58.650</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/Malaika...</td>\n",
              "      <td>https://www.gramedia.com/products/malaikat-di-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Buku Bisakah Aku yang Pelupa Memiliki Ingatan ...</td>\n",
              "      <td>Cho Shin Young</td>\n",
              "      <td>Rp 100.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/buku-bisakah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The Art of Self Talk-ing</td>\n",
              "      <td>Nisrina P. Utami None</td>\n",
              "      <td>Rp 56.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/the-art-of-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Paket Pandai Baca Tulis Hitung Anak Umur Paud ...</td>\n",
              "      <td>Kak Elly</td>\n",
              "      <td>Rp 67.150</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/paket-pandai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Kisah 25 Nabi Dan Khulafaur Rasyidin</td>\n",
              "      <td>Herdro Trilaksana</td>\n",
              "      <td>Rp 51.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/kisah-25-nab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Indonesia Sebagai Poros Maritim Dunia</td>\n",
              "      <td>Poltak Partogi Nainggolan</td>\n",
              "      <td>Rp 136.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/indonesia-se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Kitab Lulus Utbk Sbmptn Saintek 2022</td>\n",
              "      <td>Tim Guru dan Tentor Indonesia</td>\n",
              "      <td>Rp 169.150</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/kitab-lulus-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Pendidikan Untuk Apa dan Untuk Siapa?</td>\n",
              "      <td>Lucia Ratih Kusumadewi</td>\n",
              "      <td>Rp 42.500</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/pendidikan-u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Petualangan Lu si Ulat Bulu : Topi Jerami Lu</td>\n",
              "      <td>Norrattri</td>\n",
              "      <td>Rp 52.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/petualangan-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Petualangan Lu si Ulat Bulu : Apakah Lu diculik?</td>\n",
              "      <td>Norrattri</td>\n",
              "      <td>Rp 52.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/petualangan-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Kenduri Arwah</td>\n",
              "      <td>A.R Rizal</td>\n",
              "      <td>Rp 72.250</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/kenduri-arwah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Intelijen dan Kekuasaan Soeharto</td>\n",
              "      <td>Diandra Megaputri Mengko</td>\n",
              "      <td>Rp 72.250</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/intelijen-da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Petualangan Lu si Ulat Bulu : Kenari Untuk Pipu</td>\n",
              "      <td>Norrattri</td>\n",
              "      <td>Rp 52.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/petualangan-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>KOLONI Sinawang</td>\n",
              "      <td>Dedy Koerniawan Soesanto</td>\n",
              "      <td>Rp 36.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/koloni-sinawang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Plants VS Zombies - Komik Dinosaurus : Berburu...</td>\n",
              "      <td>Xiao Jiangnan</td>\n",
              "      <td>Rp 84.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/plants-vs-zo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Title  \\\n",
              "0                                                  A+   \n",
              "1                                            Lavender   \n",
              "2      Fiqih Al-Mu`Tamad Fiqih Hukum Keluarga Jilid 4   \n",
              "3                              30 Doa Salafush Shalih   \n",
              "4                Ramuan Tradisional Anti Segala Virus   \n",
              "5                               Malaikat Di Sisi Kita   \n",
              "6   Buku Bisakah Aku yang Pelupa Memiliki Ingatan ...   \n",
              "7                            The Art of Self Talk-ing   \n",
              "8   Paket Pandai Baca Tulis Hitung Anak Umur Paud ...   \n",
              "9                Kisah 25 Nabi Dan Khulafaur Rasyidin   \n",
              "10              Indonesia Sebagai Poros Maritim Dunia   \n",
              "11               Kitab Lulus Utbk Sbmptn Saintek 2022   \n",
              "12              Pendidikan Untuk Apa dan Untuk Siapa?   \n",
              "13       Petualangan Lu si Ulat Bulu : Topi Jerami Lu   \n",
              "14   Petualangan Lu si Ulat Bulu : Apakah Lu diculik?   \n",
              "15                                      Kenduri Arwah   \n",
              "16                   Intelijen dan Kekuasaan Soeharto   \n",
              "17    Petualangan Lu si Ulat Bulu : Kenari Untuk Pipu   \n",
              "18                                    KOLONI Sinawang   \n",
              "19  Plants VS Zombies - Komik Dinosaurus : Berburu...   \n",
              "\n",
              "                             Author       Price  \\\n",
              "0                     Ananda Putri    Rp 84.575   \n",
              "1              Astri Salvia Aznani    Rp 80.750   \n",
              "2    Prof. Dr. Muhammad az-Zuhaili   Rp 204.000   \n",
              "3                        OMAR None    Rp 58.650   \n",
              "4                   Argo Wikanjati    Rp 51.000   \n",
              "5                     Omar Suleman    Rp 58.650   \n",
              "6                   Cho Shin Young   Rp 100.000   \n",
              "7            Nisrina P. Utami None    Rp 56.000   \n",
              "8                         Kak Elly    Rp 67.150   \n",
              "9                Herdro Trilaksana    Rp 51.000   \n",
              "10       Poltak Partogi Nainggolan   Rp 136.000   \n",
              "11   Tim Guru dan Tentor Indonesia   Rp 169.150   \n",
              "12          Lucia Ratih Kusumadewi    Rp 42.500   \n",
              "13                      Norrattri     Rp 52.000   \n",
              "14                      Norrattri     Rp 52.000   \n",
              "15                       A.R Rizal    Rp 72.250   \n",
              "16        Diandra Megaputri Mengko    Rp 72.250   \n",
              "17                      Norrattri     Rp 52.000   \n",
              "18        Dedy Koerniawan Soesanto    Rp 36.000   \n",
              "19                   Xiao Jiangnan    Rp 84.000   \n",
              "\n",
              "                                                Image  \\\n",
              "0   https://cdn.gramedia.com/uploads/items/A__w149...   \n",
              "1   https://cdn.gramedia.com/uploads/items/Lavende...   \n",
              "2                  /assets/default-images/product.png   \n",
              "3   https://cdn.gramedia.com/uploads/items/30_Doa_...   \n",
              "4   https://cdn.gramedia.com/uploads/items/Ramuan_...   \n",
              "5   https://cdn.gramedia.com/uploads/items/Malaika...   \n",
              "6                  /assets/default-images/product.png   \n",
              "7                  /assets/default-images/product.png   \n",
              "8                  /assets/default-images/product.png   \n",
              "9                  /assets/default-images/product.png   \n",
              "10                 /assets/default-images/product.png   \n",
              "11                 /assets/default-images/product.png   \n",
              "12                 /assets/default-images/product.png   \n",
              "13                 /assets/default-images/product.png   \n",
              "14                 /assets/default-images/product.png   \n",
              "15                 /assets/default-images/product.png   \n",
              "16                 /assets/default-images/product.png   \n",
              "17                 /assets/default-images/product.png   \n",
              "18                 /assets/default-images/product.png   \n",
              "19                 /assets/default-images/product.png   \n",
              "\n",
              "                                                 Link  \n",
              "0               https://www.gramedia.com/products/a-3  \n",
              "1          https://www.gramedia.com/products/lavender  \n",
              "2   https://www.gramedia.com/products/fiqih-al-mut...  \n",
              "3   https://www.gramedia.com/products/30-doa-salaf...  \n",
              "4   https://www.gramedia.com/products/ramuan-tradi...  \n",
              "5   https://www.gramedia.com/products/malaikat-di-...  \n",
              "6   https://www.gramedia.com/products/buku-bisakah...  \n",
              "7   https://www.gramedia.com/products/the-art-of-s...  \n",
              "8   https://www.gramedia.com/products/paket-pandai...  \n",
              "9   https://www.gramedia.com/products/kisah-25-nab...  \n",
              "10  https://www.gramedia.com/products/indonesia-se...  \n",
              "11  https://www.gramedia.com/products/kitab-lulus-...  \n",
              "12  https://www.gramedia.com/products/pendidikan-u...  \n",
              "13  https://www.gramedia.com/products/petualangan-...  \n",
              "14  https://www.gramedia.com/products/petualangan-...  \n",
              "15    https://www.gramedia.com/products/kenduri-arwah  \n",
              "16  https://www.gramedia.com/products/intelijen-da...  \n",
              "17  https://www.gramedia.com/products/petualangan-...  \n",
              "18  https://www.gramedia.com/products/koloni-sinawang  \n",
              "19  https://www.gramedia.com/products/plants-vs-zo...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame()\n",
        "\n",
        "data['Title'] = [ title.get_text() for title in soup.find_all( 'div', {\"class\":\"list-title\"} ) ]\n",
        "data['Author'] = [ author.get_text() for author in soup.find_all( 'p', {\"class\":\"div-author\"} ) ]\n",
        "data['Price'] = [ price.get_text() for price in soup.find_all( 'p', {\"class\":\"formats-price\"} ) ]\n",
        "data['Image'] = [ img['src'] for img in soup.find_all( 'img',{\"class\":\"product-list-img\"} ) ]\n",
        "\n",
        "links = []\n",
        "for tag in soup.find_all( 'div',{\"_ngcontent-web-gramedia-c26\":\"\",\"class\":\"ng-star-inserted\"} ):\n",
        "    try:\n",
        "        links.append(\"https://www.gramedia.com\"+tag.find_all('a',{\"_ngcontent-web-gramedia-c26\":\"\"})[0]['href'])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "data['Link'] = links\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWnlUPJPlhnT"
      },
      "source": [
        "## Multipage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxYtCG4KlhnU"
      },
      "source": [
        "Currently, we are working on a page. However, the rest of the web consist of more pages like below:\n",
        "\n",
        "<img src=\"https://i.ibb.co/CQ6JQLv/message-Image-1636716930335.jpg\"></img>\n",
        "\n",
        "If we look at the next page such as page 2, we can see that the url change to https://www.gramedia.com/categories/buku?page=2 and page 3: https://www.gramedia.com/categories/buku?page=3. Then we know each page has a numbering format on url so we can access many pages one time automatically using loop. We exclude the image since image loader is very depended on your connection. Let's check the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EJ0FwACRlhnU",
        "outputId": "b8a20bf7-38cb-4949-8380-2ab805ed37a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dedwi\\AppData\\Local\\Temp/ipykernel_20652/3109118528.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome('./web_scraping/chromedriver.exe')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Author</th>\n",
              "      <th>Price</th>\n",
              "      <th>Image</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A+</td>\n",
              "      <td>Ananda Putri</td>\n",
              "      <td>Rp 84.575</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/A__w149...</td>\n",
              "      <td>https://www.gramedia.com/products/a-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lavender</td>\n",
              "      <td>Astri Salvia Aznani</td>\n",
              "      <td>Rp 80.750</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/Lavende...</td>\n",
              "      <td>https://www.gramedia.com/products/lavender</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fiqih Al-Mu`Tamad Fiqih Hukum Keluarga Jilid 4</td>\n",
              "      <td>Prof. Dr. Muhammad az-Zuhaili</td>\n",
              "      <td>Rp 204.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/fiqih-al-mut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30 Doa Salafush Shalih</td>\n",
              "      <td>OMAR None</td>\n",
              "      <td>Rp 58.650</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/30_Doa_...</td>\n",
              "      <td>https://www.gramedia.com/products/30-doa-salaf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ramuan Tradisional Anti Segala Virus</td>\n",
              "      <td>Argo Wikanjati</td>\n",
              "      <td>Rp 51.000</td>\n",
              "      <td>https://cdn.gramedia.com/uploads/items/Ramuan_...</td>\n",
              "      <td>https://www.gramedia.com/products/ramuan-tradi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>Kecebong K(A)Esayangan</td>\n",
              "      <td>KAESANG DAN TIM SANG JAVAS</td>\n",
              "      <td>Rp 75.650</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/kecebong-kae...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>Jodoh Sang Superstar</td>\n",
              "      <td>Santy DIliana</td>\n",
              "      <td>Rp 75.650</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/jodoh-sang-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>Haru Mahameru</td>\n",
              "      <td></td>\n",
              "      <td>Rp 58.650</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/haru-mahameru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>Ekonomi, Politik Dan Peluang Bisnis Di Negara-...</td>\n",
              "      <td>MOHAMAD BAWAZEER, DKK.</td>\n",
              "      <td>Rp 148.750</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/ekonomi-poli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>Cookie Run Sweet Escape Adventure! - Hi-Tech T...</td>\n",
              "      <td>Seoul Cultural Publisher, Inc.</td>\n",
              "      <td>Rp 68.000</td>\n",
              "      <td>/assets/default-images/product.png</td>\n",
              "      <td>https://www.gramedia.com/products/cookie-run-s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Title  \\\n",
              "0                                                   A+   \n",
              "1                                             Lavender   \n",
              "2       Fiqih Al-Mu`Tamad Fiqih Hukum Keluarga Jilid 4   \n",
              "3                               30 Doa Salafush Shalih   \n",
              "4                 Ramuan Tradisional Anti Segala Virus   \n",
              "..                                                 ...   \n",
              "395                             Kecebong K(A)Esayangan   \n",
              "396                               Jodoh Sang Superstar   \n",
              "397                                      Haru Mahameru   \n",
              "398  Ekonomi, Politik Dan Peluang Bisnis Di Negara-...   \n",
              "399  Cookie Run Sweet Escape Adventure! - Hi-Tech T...   \n",
              "\n",
              "                               Author       Price  \\\n",
              "0                       Ananda Putri    Rp 84.575   \n",
              "1                Astri Salvia Aznani    Rp 80.750   \n",
              "2      Prof. Dr. Muhammad az-Zuhaili   Rp 204.000   \n",
              "3                          OMAR None    Rp 58.650   \n",
              "4                     Argo Wikanjati    Rp 51.000   \n",
              "..                                ...         ...   \n",
              "395       KAESANG DAN TIM SANG JAVAS    Rp 75.650   \n",
              "396                    Santy DIliana    Rp 75.650   \n",
              "397                                     Rp 58.650   \n",
              "398           MOHAMAD BAWAZEER, DKK.   Rp 148.750   \n",
              "399   Seoul Cultural Publisher, Inc.    Rp 68.000   \n",
              "\n",
              "                                                 Image  \\\n",
              "0    https://cdn.gramedia.com/uploads/items/A__w149...   \n",
              "1    https://cdn.gramedia.com/uploads/items/Lavende...   \n",
              "2                   /assets/default-images/product.png   \n",
              "3    https://cdn.gramedia.com/uploads/items/30_Doa_...   \n",
              "4    https://cdn.gramedia.com/uploads/items/Ramuan_...   \n",
              "..                                                 ...   \n",
              "395                 /assets/default-images/product.png   \n",
              "396                 /assets/default-images/product.png   \n",
              "397                 /assets/default-images/product.png   \n",
              "398                 /assets/default-images/product.png   \n",
              "399                 /assets/default-images/product.png   \n",
              "\n",
              "                                                  Link  \n",
              "0                https://www.gramedia.com/products/a-3  \n",
              "1           https://www.gramedia.com/products/lavender  \n",
              "2    https://www.gramedia.com/products/fiqih-al-mut...  \n",
              "3    https://www.gramedia.com/products/30-doa-salaf...  \n",
              "4    https://www.gramedia.com/products/ramuan-tradi...  \n",
              "..                                                 ...  \n",
              "395  https://www.gramedia.com/products/kecebong-kae...  \n",
              "396  https://www.gramedia.com/products/jodoh-sang-s...  \n",
              "397    https://www.gramedia.com/products/haru-mahameru  \n",
              "398  https://www.gramedia.com/products/ekonomi-poli...  \n",
              "399  https://www.gramedia.com/products/cookie-run-s...  \n",
              "\n",
              "[400 rows x 5 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from time import sleep\n",
        "from random import randint\n",
        "title = []\n",
        "author = []\n",
        "price = []\n",
        "image = []\n",
        "Links = []\n",
        "\n",
        "driver = webdriver.Chrome('./web_scraping/chromedriver.exe')\n",
        "\n",
        "for i in range(1,21):\n",
        "    url=\"https://www.gramedia.com/categories/buku?page={}\".format(i)\n",
        "    driver.get(url)\n",
        "    sleep(randint(20,25))\n",
        "\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    title += [ title.get_text() for title in soup.find_all( 'div', {\"class\":\"list-title\"} ) ]\n",
        "    author += [ author.get_text() for author in soup.find_all( 'p', {\"class\":\"div-author\"} ) ]\n",
        "    price += [ price.get_text() for price in soup.find_all( 'p', {\"class\":\"formats-price\"} ) ]\n",
        "    image += [ img['src'] for img in soup.find_all( 'img',{\"class\":\"product-list-img\"} ) ]\n",
        "\n",
        "    links = []\n",
        "    for tag in soup.find_all( 'div',{\"_ngcontent-web-gramedia-c26\":\"\",\"class\":\"ng-star-inserted\"} ):\n",
        "        try:\n",
        "            links.append(\"https://www.gramedia.com\"+tag.find_all('a',{\"_ngcontent-web-gramedia-c26\":\"\"})[0]['href'])\n",
        "        except:\n",
        "            pass\n",
        "    Links += links\n",
        "\n",
        "data_multipage = pd.DataFrame()\n",
        "data_multipage['Title'] = title\n",
        "data_multipage['Author'] = author\n",
        "data_multipage['Price'] = price\n",
        "data_multipage['Image'] = image\n",
        "data_multipage['Link'] = Links\n",
        "\n",
        "data_multipage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueJYOlHglhnU"
      },
      "source": [
        "## Accessing Individual Page\n",
        "\n",
        "<img src=\"https://i.ibb.co/F8D5bCy/message-Image-1637134633305.jpg\"></img>\n",
        "\n",
        "Suppose that we want to get more detail information about the books, but the information are on the individual page. So, we will access the individual page and scrape some information on it. We will catch title, author, price, description, number of pages, date of issue and publisher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8VNolUnlhnU",
        "outputId": "223292ff-fb9a-4242-e826-968d25b4176c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/jn/3zxggwvn0w9fxzbpwtz0q8p80000gn/T/ipykernel_46944/2279684204.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome('/Users/fahmimn21/Downloads/chromedriver')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Author</th>\n",
              "      <th>Price</th>\n",
              "      <th>Desc</th>\n",
              "      <th>Num Pages</th>\n",
              "      <th>Date Issue</th>\n",
              "      <th>Publisher</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Semangat Baja Ibnu Sutanto</td>\n",
              "      <td>Robert Adhi Ksp</td>\n",
              "      <td>Rp 100.000</td>\n",
              "      <td>Buku Semangat Baja Ibnu Su...</td>\n",
              "      <td>350.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Pbk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Think And Grow Rich : Cara Para Jutawan Dan Mi...</td>\n",
              "      <td>Napoleon Hill</td>\n",
              "      <td>Rp 77.000</td>\n",
              "      <td>Kekayaan dimulai dengan ke...</td>\n",
              "      <td>364.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Bhuana Ilmu Populer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kitty dan Tragedi di Pekan Raya</td>\n",
              "      <td>PAULA HARRISON</td>\n",
              "      <td>Rp 67.000</td>\n",
              "      <td>Kitty sangat ingin pergi k...</td>\n",
              "      <td>128.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Bhuana Ilmu Populer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hoegeng Polisi dan Menteri Teladan Edisi Revisi</td>\n",
              "      <td>Suhartono</td>\n",
              "      <td>Rp 75.000</td>\n",
              "      <td>Namun, bagaimana kiprah Ho...</td>\n",
              "      <td>300.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Pbk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lil` Sis Please Cook For me! 02</td>\n",
              "      <td>IUNOSU</td>\n",
              "      <td>Rp 40.000</td>\n",
              "      <td>Yuzuki akhirnya mulai terb...</td>\n",
              "      <td>200.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Elex Media Komputindo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Detektif Conan Premium 09</td>\n",
              "      <td>Aoyama Gosho</td>\n",
              "      <td>Rp 65.000</td>\n",
              "      <td>Kogoro Mouri menerima sepu...</td>\n",
              "      <td>368.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Elex Media Komputindo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Kumpulan Latihan PHP</td>\n",
              "      <td>Eri Mardiani</td>\n",
              "      <td>Rp 75.000</td>\n",
              "      <td>Saat ini pemrograman sanga...</td>\n",
              "      <td>224.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Elex Media Komputindo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Only Human (Themis Files #3)</td>\n",
              "      <td>Sylvain Neuvel</td>\n",
              "      <td>Rp 110.000</td>\n",
              "      <td>Sebentuk tangan raksasa ta...</td>\n",
              "      <td>408.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Elex Media Komputindo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Mereka yang Tak Kembali (Long Bright River)</td>\n",
              "      <td>Liz Moore</td>\n",
              "      <td>Rp 129.000</td>\n",
              "      <td>Jalanan kota Philadelphia ...</td>\n",
              "      <td>392.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Gramedia Pustaka Utama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MetroPop: Saat-Saat Jauh</td>\n",
              "      <td>Lia Seplia</td>\n",
              "      <td>Rp 87.000</td>\n",
              "      <td>Aline dan Alex saling perc...</td>\n",
              "      <td>280.0</td>\n",
              "      <td>17 Nov 2021</td>\n",
              "      <td>Gramedia Pustaka Utama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Love Yourself</td>\n",
              "      <td>Dr Jiemi Ardian</td>\n",
              "      <td>Rp 60.000</td>\n",
              "      <td>\"Pengetahuan tidak membuat...</td>\n",
              "      <td>200.0</td>\n",
              "      <td>15 Nov 2021</td>\n",
              "      <td>Yrama Widya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Karya Tulis Ilmiah : Teori Dan Terapan</td>\n",
              "      <td>DR.ERIZAL GANI,M.PD</td>\n",
              "      <td>Rp 97.500</td>\n",
              "      <td>Benarkah menulis karya ilm...</td>\n",
              "      <td>400.0</td>\n",
              "      <td>15 Nov 2021</td>\n",
              "      <td>Pustaka Reka Cipta</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Title               Author  \\\n",
              "0                          Semangat Baja Ibnu Sutanto      Robert Adhi Ksp   \n",
              "1   Think And Grow Rich : Cara Para Jutawan Dan Mi...        Napoleon Hill   \n",
              "2                     Kitty dan Tragedi di Pekan Raya       PAULA HARRISON   \n",
              "3     Hoegeng Polisi dan Menteri Teladan Edisi Revisi            Suhartono   \n",
              "4                     Lil` Sis Please Cook For me! 02               IUNOSU   \n",
              "5                           Detektif Conan Premium 09         Aoyama Gosho   \n",
              "6                                Kumpulan Latihan PHP         Eri Mardiani   \n",
              "7                        Only Human (Themis Files #3)       Sylvain Neuvel   \n",
              "8         Mereka yang Tak Kembali (Long Bright River)            Liz Moore   \n",
              "9                            MetroPop: Saat-Saat Jauh           Lia Seplia   \n",
              "10                                      Love Yourself      Dr Jiemi Ardian   \n",
              "11             Karya Tulis Ilmiah : Teori Dan Terapan  DR.ERIZAL GANI,M.PD   \n",
              "\n",
              "         Price                                               Desc Num Pages  \\\n",
              "0   Rp 100.000                      Buku Semangat Baja Ibnu Su...     350.0   \n",
              "1    Rp 77.000                      Kekayaan dimulai dengan ke...     364.0   \n",
              "2    Rp 67.000                      Kitty sangat ingin pergi k...     128.0   \n",
              "3    Rp 75.000                      Namun, bagaimana kiprah Ho...     300.0   \n",
              "4    Rp 40.000                      Yuzuki akhirnya mulai terb...     200.0   \n",
              "5    Rp 65.000                      Kogoro Mouri menerima sepu...     368.0   \n",
              "6    Rp 75.000                      Saat ini pemrograman sanga...     224.0   \n",
              "7   Rp 110.000                      Sebentuk tangan raksasa ta...     408.0   \n",
              "8   Rp 129.000                      Jalanan kota Philadelphia ...     392.0   \n",
              "9    Rp 87.000                      Aline dan Alex saling perc...     280.0   \n",
              "10   Rp 60.000                      \"Pengetahuan tidak membuat...     200.0   \n",
              "11   Rp 97.500                      Benarkah menulis karya ilm...     400.0   \n",
              "\n",
              "     Date Issue               Publisher  \n",
              "0   17 Nov 2021                     Pbk  \n",
              "1   17 Nov 2021     Bhuana Ilmu Populer  \n",
              "2   17 Nov 2021     Bhuana Ilmu Populer  \n",
              "3   17 Nov 2021                     Pbk  \n",
              "4   17 Nov 2021   Elex Media Komputindo  \n",
              "5   17 Nov 2021   Elex Media Komputindo  \n",
              "6   17 Nov 2021   Elex Media Komputindo  \n",
              "7   17 Nov 2021   Elex Media Komputindo  \n",
              "8   17 Nov 2021  Gramedia Pustaka Utama  \n",
              "9   17 Nov 2021  Gramedia Pustaka Utama  \n",
              "10  15 Nov 2021             Yrama Widya  \n",
              "11  15 Nov 2021      Pustaka Reka Cipta  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "title = []\n",
        "author = []\n",
        "price = []\n",
        "desc = []\n",
        "num_pages = []\n",
        "date_issue = []\n",
        "publisher = []\n",
        "\n",
        "driver = webdriver.Chrome('/Users/fahmimn21/Downloads/chromedriver')\n",
        "\n",
        "for i in range(1,3):\n",
        "    url=\"https://www.gramedia.com/categories/buku?page={}\".format(i)\n",
        "    driver.get(url)\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    for tag in soup.find_all( 'div',{\"_ngcontent-web-gramedia-c26\":\"\",\"class\":\"ng-star-inserted\"} ):\n",
        "        try:\n",
        "            link = \"https://www.gramedia.com\"+tag.find('a',{\"_ngcontent-web-gramedia-c26\":\"\"})['href']\n",
        "            driver.get(link)\n",
        "            html_ind = driver.page_source\n",
        "            soup_ind = BeautifulSoup(html_ind, \"html.parser\")\n",
        "\n",
        "            title.append( soup_ind.find( 'div', {\"class\":\"book-title\"} ).get_text() )\n",
        "            author.append( soup_ind.find('span',{\"class\":\"title-author\"}).get_text() )\n",
        "            price.append( soup_ind.find('div', {'class':'price-product'}).get_text() )\n",
        "            desc.append( soup_ind.find('pre').get_text() )\n",
        "            num_pages.append( soup_ind.find('div',{'class':'detail-section'}).find_all('p')[0].get_text() )\n",
        "            date_issue.append( soup_ind.find('div',{'class':'detail-section'}).find_all('p')[2].get_text() )\n",
        "            publisher.append( soup_ind.find('div',{'class':'detail-section'}).find_all('p')[1].get_text() )\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "pages = pd.DataFrame()\n",
        "pages['Title'] = title\n",
        "pages['Author'] = author\n",
        "pages['Price'] = price\n",
        "pages['Desc'] = desc\n",
        "pages['Num Pages'] = num_pages\n",
        "pages['Date Issue'] = date_issue\n",
        "pages['Publisher'] = publisher\n",
        "\n",
        "pages"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "d1pm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
